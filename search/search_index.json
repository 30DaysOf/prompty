{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>By definition, Prompty is a new asset class and format for LLM prompts that aims to provide observability, understandability, and portability for developers. In this workshop, we explore what this means from core concepts to prompty prototyping in a series of hands-on labs.</p> <p></p>"},{"location":"#learning-objectives","title":"Learning Objectives","text":"<p>The workshop is structured as a series of hands-on labs taking you from core concepts to prompt evaluation and composition, with code. On completion, you should be able to describe:</p> <ol> <li>What Prompty is and the benefits it offers</li> <li>How to create and execute a simple Prompty asset</li> <li>How to choose and configure models for your prompt</li> <li>How to engineer prompts for different scenarios</li> <li>How to instrument Prompty assets for observability</li> <li>How to evaluate prompts to assess quality and safety</li> <li>How to compose Prompty assets for complex flows</li> </ol>"},{"location":"#pre-requisites","title":"Pre-Requisites","text":"<p>To complete these labs you will need:</p> <ol> <li>A personal GitHub account (create one for free)</li> <li>A Microsoft Azure account (create one for free)</li> <li>Basic familiarity with Python syntax and tools</li> <li>Basic familiarity with Generative AI concepts</li> <li>Basic familiarity with Visual Studio Code tooling</li> </ol>"},{"location":"#learning-modules","title":"Learning Modules","text":"<p>The workshop is organized into modules, each focused on one topic and containing a series of hands-on lab units. Click the module title to see details of the units.</p> 1. Core Concepts <ul> <li>Prompty Specification</li> <li>Prompty Tooling</li> <li>Prompty Runtime</li> </ul> 2. Prompty Quickstart <ul> <li>Create a new Prompty asset</li> <li>Configure asset with a model</li> <li>Configure asset with a prompty template</li> <li>Execute asset with a hardcoded input</li> </ul> 3. Prompt Engineering <ul> <li>By modifying model parameters</li> <li>By modifying system context</li> <li>By modifying prompt instructions</li> <li>By adding grounding context</li> </ul> 4. Model Choice <p>Refactor prompty asset to use models sourced from:</p> <ul> <li>GitHub Marketplace</li> <li>Open AI </li> <li>Azure OpenAI </li> <li>Azure AI Model Catalog (serverless API)</li> <li>LlamaIndex </li> </ul> 5. Prompty Observability <ul> <li>Instrumenting assets for tracing</li> <li>Viewing trace logs in the Prompty UI</li> </ul> 6. Prompty Testing <ul> <li>With a sample data file</li> <li>With hardcoded data inputs</li> <li>With interactive data inputs from CLI</li> </ul> 7. Prompty Composition <ul> <li>Chain prompty assets for evaluation</li> <li>Chain prompty assets for orchestration</li> </ul> 8. Prompty Evaluation <ul> <li>By writing custom evaluators</li> <li>By running evaluators with test data</li> <li>By assessing quality with test data</li> <li>By running evaluators with adversarial data</li> <li>By assessing safety with adversarial data</li> </ul>"},{"location":"#learning-resources","title":"Learning Resources","text":"<p>Bookmark and explore these resources:</p> <ul> <li>Documentation - official documentation, in-progress.</li> <li>Repository - open-source repository.</li> <li>Prompty in Promptflow - with examples</li> </ul> <p>Watch the Microsoft Build 2024 session for a practical tour of end-to-end usage.</p>"},{"location":"1.%20Core%20Concepts/01/","title":"1. Introduction","text":"<p>Building production-ready generative AI applications involves 3 stages:</p> <ul> <li>Ideation - rapid prototyping, testing apps with simple test prompts.</li> <li>Augmentation - evaluation, testing quality &amp; safety with larger datasets.</li> <li>Operationalization - deploying apps and monitoring them for insights.</li> </ul> <p>The challenge is in providing developers with a developer experience and tooling support to streamline these stages - without requiring a massive learning curve in new semantics, model-specific APIs or plaform-specific SDKs. </p> <p>What if we could make the prompt the central unit of development - and build tooling to build agency and observability around it? That's the vision behind Prompty. Watch this Microsoft Build 2024 session for a deeper dive into end-to-end AI development using Prompty and AI Studio.</p> <p>Using Prompty you can:</p> <ul> <li>Design Prompts - Create &amp; refine prompt templates in an IDE</li> <li>Explore Models - Configure model parameters, diverse deployments</li> <li>Execute Prompts - Use built-in tools and custom runtimes to test prompts</li> <li>Observe Traces - Use built-in features to track and debug execution</li> <li>Compose Apps - Chain and compose Prompty assets for complex flows</li> </ul>"},{"location":"1.%20Core%20Concepts/02/","title":"2. Specification","text":""},{"location":"1.%20Core%20Concepts/03/","title":"3. Tooling","text":""},{"location":"1.%20Core%20Concepts/04/","title":"4. Runtime","text":""},{"location":"2.%20Prompty%20Quickstart/01/","title":"Create Prompty","text":""},{"location":"2.%20Prompty%20Quickstart/02/","title":"Configure Models","text":""},{"location":"2.%20Prompty%20Quickstart/03/","title":"Create Sample","text":""},{"location":"2.%20Prompty%20Quickstart/04/","title":"Run Prompty","text":""},{"location":"3.%20Prompt%20Engineering/01/","title":"System Context","text":""},{"location":"3.%20Prompt%20Engineering/02/","title":"Prompt Instructions","text":""},{"location":"3.%20Prompt%20Engineering/03/","title":"Model Parameters","text":""},{"location":"3.%20Prompt%20Engineering/04/","title":"Add Data","text":""},{"location":"4.%20Model%20Choice/01/","title":"Open AI","text":""},{"location":"4.%20Model%20Choice/02/","title":"Azure Open AI","text":""},{"location":"4.%20Model%20Choice/03/","title":"Azure Serverless","text":""},{"location":"4.%20Model%20Choice/04/","title":"GitHub Marketplace","text":""},{"location":"5.%20Observability/01/","title":"Prompty Tracing","text":""},{"location":"5.%20Observability/02/","title":"Trace Decorators","text":""},{"location":"5.%20Observability/03/","title":"Trace Runs","text":""},{"location":"5.%20Observability/04/","title":"Open Telemetry","text":""},{"location":"6.%20Testing/01/","title":"Hardcoded Input","text":""},{"location":"6.%20Testing/02/","title":"Sample File","text":""},{"location":"6.%20Testing/03/","title":"Commandline Input","text":""},{"location":"6.%20Testing/04/","title":"Function Call","text":""},{"location":"7.%20Compostion/01/","title":"Prompty + Data Binding","text":""},{"location":"7.%20Compostion/02/","title":"Prompty + RAG Pattern","text":""},{"location":"7.%20Compostion/03/","title":"Prompty + Evaluation","text":""},{"location":"7.%20Compostion/04/","title":"Prompty + Multi-Agent","text":""},{"location":"8.%20Evaluation/01/","title":"AI-Assisted Evaluation","text":""},{"location":"8.%20Evaluation/02/","title":"Evaluation Metrics","text":""},{"location":"8.%20Evaluation/03/","title":"Evaluation Test Data","text":""},{"location":"8.%20Evaluation/04/","title":"Evaluation Workflow","text":""}]}